{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#from dotenv import load_dotenv  \n",
    "\n",
    "# Load environment variables from .env file\n",
    "#load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Initialiser le client OpenAI avec la clé \n",
    "\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "def gen_val_qa_pairs(topic, num_pairs):\n",
    "    qa_pairs = []\n",
    "\n",
    "    for _ in range(num_pairs):\n",
    "        # Générer une question\n",
    "        prompt_question = f\"Generate a complex question about {topic}.\"\n",
    "        response_question = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_question}]\n",
    "        )\n",
    "        question = response_question.choices[0].message.content.strip()\n",
    "\n",
    "        # Générer une réponse à la question\n",
    "        prompt_answer = f\"Answer the following question in detail: {question}\"\n",
    "        response_answer = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_answer}]\n",
    "        )\n",
    "        answer = response_answer.choices[0].message.content.strip()\n",
    "\n",
    "        qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    return qa_pairs\n",
    "\n",
    "# Génération des paires question-réponse\n",
    "topic = \"finance\"\n",
    "qa_pairs = gen_val_qa_pairs(topic, 5)  # Générer 5 paires pour l'exemple\n",
    "\n",
    "# Conversion en DataFrame pandas\n",
    "qa_df = pd.DataFrame(qa_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  How does the practice of utilizing derivatives...   \n",
      "1  What are the primary factors that contribute t...   \n",
      "2  What is the impact of macroeconomic policies, ...   \n",
      "3  What are the key factors influencing the price...   \n",
      "4  How does the interaction of monetary policy, i...   \n",
      "\n",
      "                                              answer  \n",
      "0  The practice of utilizing derivatives has a si...  \n",
      "1  The risk-return relationship in financial mark...  \n",
      "2  Macroeconomic policies, including fiscal and m...  \n",
      "3  The key factors influencing the price movement...  \n",
      "4  The interaction between monetary policy, infla...  \n"
     ]
    }
   ],
   "source": [
    "# Affichage du DataFrame\n",
    "print(qa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(category, prompt, num_questions):\n",
    "    questions = []\n",
    "    for _ in range(num_questions):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        question = response.choices[0].message.content.strip()\n",
    "        questions.append({\"Category\": category, \"Question\": question})\n",
    "    return questions\n",
    "\n",
    "# Définissez les prompts pour chaque catégorie de question\n",
    "categories_prompts = {\n",
    "    \"Clarifying\": \"Generate a clarifying question for a team discussion. Example: 'Can you tell me more about your idea?'\",\n",
    "    \"Probing\": \"Generate a probing question to challenge an idea. Example: 'Do you think this is going to work? Why?'\",\n",
    "    \"Exploratory\": \"Generate an exploratory question to consider different scenarios. Example: 'What are the long-term effects of this approach?'\",\n",
    "    \"Generative\": \"Generate a generative question to identify new solutions. Example: 'What other possible solutions can we consider?'\"\n",
    "}\n",
    "\n",
    "# Nombre total de questions souhaité\n",
    "total_questions = 16  # Exemple : 100 questions au total\n",
    "questions_per_category = total_questions // len(categories_prompts)  # Répartition équitable\n",
    "\n",
    "# Génération du dataset\n",
    "dataset = []\n",
    "for category, prompt in categories_prompts.items():\n",
    "    dataset.extend(generate_questions(category, prompt, questions_per_category))\n",
    "\n",
    "# Conversion en DataFrame pandas\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Category                                           Question  \\\n",
      "0   Clarifying  Could you please clarify what specific aspect ...   \n",
      "1   Clarifying  What specific aspects or applications of Artif...   \n",
      "2      Probing  How would you address concerns about the poten...   \n",
      "3      Probing  What are some potential ethical concerns or ri...   \n",
      "4  Exploratory  What are the potential ethical implications an...   \n",
      "5  Exploratory  What are the potential ethical implications of...   \n",
      "6   Generative  How can artificial intelligence be used to enh...   \n",
      "7   Generative  How can we develop smarter artificial intellig...   \n",
      "\n",
      "                                              Answer  \n",
      "0  I am referring to a specific aspect or applica...  \n",
      "1  I am referring to the various subfields and ap...  \n",
      "2  There are a few ways I would address concerns ...  \n",
      "3  There are several potential ethical concerns a...  \n",
      "4  The potential ethical implications and consequ...  \n",
      "5  The widespread adoption of Artificial Intellig...  \n",
      "6  Artificial intelligence (AI) can significantly...  \n",
      "7  There are several approaches that can be taken...  \n"
     ]
    }
   ],
   "source": [
    "def generate_qa_pairs(category, description, topic, num_pairs):\n",
    "    qa_pairs = []\n",
    "    for _ in range(num_pairs):\n",
    "        # Générer une question basée sur le sujet et la catégorie\n",
    "        prompt_question = f\"Generate a {category.lower()} question about {topic}. {description}\"\n",
    "        response_question = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_question}]\n",
    "        )\n",
    "        question = response_question.choices[0].message.content.strip()\n",
    "        \n",
    "        # Générer une réponse à cette question\n",
    "        prompt_answer = f\"How would you answer this {category.lower()} question about {topic}: '{question}'?\"\n",
    "        response_answer = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_answer}]\n",
    "        )\n",
    "        answer = response_answer.choices[0].message.content.strip()\n",
    "        \n",
    "        qa_pairs.append({\"Category\": category, \"Question\": question, \"Answer\": answer})\n",
    "    return qa_pairs\n",
    "\n",
    "# Sujet pour les questions\n",
    "topic = \"Artificial Intelligence\"\n",
    "\n",
    "# Description pour chaque catégorie de question\n",
    "categories_descriptions = {\n",
    "    \"Clarifying\": \"Clarifying questions aim to better understand the speaker's intent before jumping to conclusions.\",\n",
    "    \"Probing\": \"Probing questions challenge the speaker's views or ideas, often to highlight flaws.\",\n",
    "    \"Exploratory\": \"Exploratory questions help consider different scenarios and possibilities.\",\n",
    "    \"Generative\": \"Generative questions identify new solutions or improve upon existing ones.\"\n",
    "}\n",
    "\n",
    "# Nombre total de paires QA souhaité par catégorie\n",
    "num_pairs_per_category = 2\n",
    "\n",
    "# Génération du dataset\n",
    "dataset = []\n",
    "for category, description in categories_descriptions.items():\n",
    "    dataset.extend(generate_qa_pairs(category, description, topic, num_pairs_per_category))\n",
    "\n",
    "# Conversion en DataFrame pandas\n",
    "ds = pd.DataFrame(dataset)\n",
    "\n",
    "# Affichage du DataFrame\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'URL' from 'sqlalchemy' (c:\\Users\\Zakar\\anaconda3\\lib\\site-packages\\sqlalchemy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApifyDatasetLoader\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapify_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApifyClient\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorstoreIndexCreator\n\u001b[0;32m      9\u001b[0m APIFY_API_TOKEN \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPIFY_API_TOKEN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Initialisation du client Apify\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zakar\\anaconda3\\lib\\site-packages\\langchain\\indexes\\__init__.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Code to support various indexing workflows.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mProvides code to:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mdocuments that were derived from parent documents by chunking.)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexingResult, aindex, index\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sql_record_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLRecordManager\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphIndexCreator\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorstoreIndexCreator\n",
      "File \u001b[1;32mc:\\Users\\Zakar\\anaconda3\\lib\\site-packages\\langchain\\indexes\\_sql_record_manager.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, AsyncGenerator, Dict, Generator, List, Optional, Sequence, Union\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     URL,\n\u001b[0;32m     23\u001b[0m     Column,\n\u001b[0;32m     24\u001b[0m     Engine,\n\u001b[0;32m     25\u001b[0m     Float,\n\u001b[0;32m     26\u001b[0m     Index,\n\u001b[0;32m     27\u001b[0m     String,\n\u001b[0;32m     28\u001b[0m     UniqueConstraint,\n\u001b[0;32m     29\u001b[0m     and_,\n\u001b[0;32m     30\u001b[0m     create_engine,\n\u001b[0;32m     31\u001b[0m     delete,\n\u001b[0;32m     32\u001b[0m     select,\n\u001b[0;32m     33\u001b[0m     text,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyncio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     36\u001b[0m     AsyncEngine,\n\u001b[0;32m     37\u001b[0m     AsyncSession,\n\u001b[0;32m     38\u001b[0m     async_sessionmaker,\n\u001b[0;32m     39\u001b[0m     create_async_engine,\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeclarative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m declarative_base\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'URL' from 'sqlalchemy' (c:\\Users\\Zakar\\anaconda3\\lib\\site-packages\\sqlalchemy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# pip3 install flask-sqlalchemy --user\n",
    "# pip install apify-client --upgrade --quiet  \n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import ApifyDatasetLoader\n",
    "from apify_client import ApifyClient\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "APIFY_API_TOKEN = os.getenv('APIFY_API_TOKEN')\n",
    "\n",
    "# Initialisation du client Apify\n",
    "apify = ApifyClient(APIFY_API_TOKEN)\n",
    "\n",
    "# Appel de l'acteur pour obtenir le texte des pages web crawlées\n",
    "actor_call = apify.actor(\"apify/website-content-crawler\").call(\n",
    "    run_input={\"startUrls\": [{\"url\": \"https://python.langchain.com/en/latest/\"}]},\n",
    ")\n",
    "\n",
    "loader = ApifyDatasetLoader(\n",
    "    dataset_id=actor_call[\"defaultDatasetId\"],\n",
    "    dataset_mapping_function=lambda item: Document(\n",
    "        page_content=item[\"text\"] or \"\", metadata={\"source\": item[\"url\"]}\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Création d'un index vectoriel basé sur les données crawlées\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "\n",
    "# Requête dans l'index vectoriel\n",
    "query = \"Are any OpenAI chat models integrated in LangChain?\"\n",
    "result = index.query_with_sources(query)\n",
    "print(result[\"answer\"])\n",
    "print(result[\"sources\"])\n",
    "#result = index.query(query)\n",
    "#print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
